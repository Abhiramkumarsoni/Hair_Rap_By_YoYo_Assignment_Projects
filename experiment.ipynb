{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§ª No-Show Prediction â€” Experiment Notebook\n",
                "\n",
                "This notebook builds a **No-Show Prediction** model using **XGBoost** with **SMOTE** for handling class imbalance.\n",
                "\n",
                "**Pipeline:**\n",
                "1. Setup & Imports\n",
                "2. Load Data\n",
                "3. Exploratory Data Analysis (EDA)\n",
                "4. Feature Engineering\n",
                "5. Train/Test Split + SMOTE\n",
                "6. XGBoost Model Training\n",
                "7. Evaluation & Visualization\n",
                "8. Save Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (uncomment and run once if needed)\n",
                "# %pip install pandas numpy scikit-learn xgboost imbalanced-learn matplotlib seaborn joblib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import os\n",
                "import json\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# ML\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score,\n",
                "    f1_score, roc_auc_score, classification_report,\n",
                "    confusion_matrix, roc_curve\n",
                ")\n",
                "\n",
                "# XGBoost\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "# SMOTE for handling class imbalance\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
                "print(\"âœ… All imports loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Project paths\n",
                "PROJECT_ROOT = os.path.abspath(\".\")\n",
                "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"salon_bookings.csv\")\n",
                "MODELS_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
                "\n",
                "print(f\"Project Root : {PROJECT_ROOT}\")\n",
                "print(f\"Data Path    : {DATA_PATH}\")\n",
                "print(f\"Models Dir   : {MODELS_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(DATA_PATH)\n",
                "print(f\"Dataset shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Target Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Count plot\n",
                "target_counts = df[\"appointment_outcome\"].value_counts()\n",
                "colors = [\"#2ecc71\", \"#e74c3c\"]\n",
                "axes[0].bar(target_counts.index, target_counts.values, color=colors, edgecolor=\"white\")\n",
                "axes[0].set_title(\"Appointment Outcome Distribution\", fontweight=\"bold\")\n",
                "axes[0].set_ylabel(\"Count\")\n",
                "for i, (label, count) in enumerate(zip(target_counts.index, target_counts.values)):\n",
                "    axes[0].text(i, count + 50, f\"{count:,}\", ha=\"center\", fontweight=\"bold\")\n",
                "\n",
                "# Pie chart\n",
                "axes[1].pie(target_counts.values, labels=target_counts.index, autopct=\"%1.1f%%\",\n",
                "            colors=colors, startangle=90, textprops={\"fontsize\": 12})\n",
                "axes[1].set_title(\"No-Show Rate\", fontweight=\"bold\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "noshow_rate = (df['appointment_outcome'] == 'No-Show').mean()\n",
                "print(f\"\\nNo-Show Rate: {noshow_rate:.1%}\")\n",
                "print(f\"Class imbalance â€” this is why we need SMOTE!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Missing Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing = df.isnull().sum()\n",
                "if missing.sum() == 0:\n",
                "    print(\"âœ… No missing values found!\")\n",
                "else:\n",
                "    print(\"âš  Missing values:\")\n",
                "    print(missing[missing > 0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Key Feature Distributions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
                "\n",
                "# Booking lead time\n",
                "sns.histplot(data=df, x=\"booking_lead_time_days\", hue=\"appointment_outcome\",\n",
                "             kde=True, ax=axes[0, 0], palette=colors)\n",
                "axes[0, 0].set_title(\"Booking Lead Time\")\n",
                "\n",
                "# Appointment hour\n",
                "sns.histplot(data=df, x=\"appointment_hour\", hue=\"appointment_outcome\",\n",
                "             kde=True, ax=axes[0, 1], palette=colors)\n",
                "axes[0, 1].set_title(\"Appointment Hour\")\n",
                "\n",
                "# Customer age\n",
                "sns.histplot(data=df, x=\"customer_age\", hue=\"appointment_outcome\",\n",
                "             kde=True, ax=axes[0, 2], palette=colors)\n",
                "axes[0, 2].set_title(\"Customer Age\")\n",
                "\n",
                "# Past visit count\n",
                "sns.histplot(data=df, x=\"past_visit_count\", hue=\"appointment_outcome\",\n",
                "             kde=True, ax=axes[1, 0], palette=colors)\n",
                "axes[1, 0].set_title(\"Past Visit Count\")\n",
                "\n",
                "# Past no-show count\n",
                "sns.histplot(data=df, x=\"past_no_show_count\", hue=\"appointment_outcome\",\n",
                "             kde=True, ax=axes[1, 1], palette=colors)\n",
                "axes[1, 1].set_title(\"Past No-Show Count\")\n",
                "\n",
                "# Weekend vs Weekday\n",
                "weekend_noshow = df.groupby([\"is_weekend\", \"appointment_outcome\"]).size().unstack(fill_value=0)\n",
                "weekend_noshow.plot(kind=\"bar\", ax=axes[1, 2], color=colors, edgecolor=\"white\")\n",
                "axes[1, 2].set_title(\"Weekend vs Weekday\")\n",
                "axes[1, 2].set_xticklabels([\"Weekday\", \"Weekend\"], rotation=0)\n",
                "\n",
                "plt.suptitle(\"Feature Distributions by Appointment Outcome\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# No-show rate by categorical features\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "for ax, col in zip(axes, [\"service_type\", \"payment_method\", \"branch\"]):\n",
                "    noshow_rate = df.groupby(col)[\"appointment_outcome\"].apply(\n",
                "        lambda x: (x == \"No-Show\").mean()\n",
                "    ).sort_values(ascending=False)\n",
                "    noshow_rate.plot(kind=\"barh\", ax=ax, color=\"#e74c3c\", edgecolor=\"white\")\n",
                "    ax.set_title(f\"No-Show Rate by {col}\", fontweight=\"bold\")\n",
                "    ax.set_xlabel(\"No-Show Rate\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Feature Engineering\n",
                "\n",
                "Replicating the logic from `src/feature_engineering.py` inline for full control."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = df.copy()\n",
                "\n",
                "# â”€â”€ Derived Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "# No-show ratio: historical no-show tendency\n",
                "data[\"no_show_ratio\"] = data[\"past_no_show_count\"] / (data[\"past_visit_count\"] + 1)\n",
                "\n",
                "# Cancellation ratio: historical cancellation tendency\n",
                "data[\"cancellation_ratio\"] = data[\"past_cancellation_count\"] / (data[\"past_visit_count\"] + 1)\n",
                "\n",
                "# Is new customer (first visit)\n",
                "data[\"is_new_customer\"] = (data[\"past_visit_count\"] <= 1).astype(int)\n",
                "\n",
                "# Is loyal customer (10+ visits)\n",
                "data[\"is_loyal_customer\"] = (data[\"past_visit_count\"] >= 10).astype(int)\n",
                "\n",
                "# Lead time buckets\n",
                "data[\"lead_time_bucket\"] = pd.cut(\n",
                "    data[\"booking_lead_time_days\"],\n",
                "    bins=[0, 1, 3, 7, 14, 30],\n",
                "    labels=[\"same_day\", \"1-3_days\", \"4-7_days\", \"1-2_weeks\", \"2+_weeks\"],\n",
                "    include_lowest=True\n",
                ")\n",
                "\n",
                "# Hour buckets\n",
                "data[\"hour_bucket\"] = pd.cut(\n",
                "    data[\"appointment_hour\"],\n",
                "    bins=[8, 11, 14, 17, 21],\n",
                "    labels=[\"morning\", \"midday\", \"afternoon\", \"evening\"],\n",
                "    include_lowest=True\n",
                ")\n",
                "\n",
                "# Age group\n",
                "data[\"age_group\"] = pd.cut(\n",
                "    data[\"customer_age\"],\n",
                "    bins=[17, 25, 35, 45, 65],\n",
                "    labels=[\"18-25\", \"26-35\", \"36-45\", \"46+\"],\n",
                "    include_lowest=True\n",
                ")\n",
                "\n",
                "print(\"âœ… Derived features created\")\n",
                "print(f\"   no_show_ratio, cancellation_ratio, is_new_customer, is_loyal_customer,\")\n",
                "print(f\"   lead_time_bucket, hour_bucket, age_group\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Encode Categoricals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "categorical_cols = [\n",
                "    \"service_type\", \"payment_method\", \"branch\", \"day_of_week\",\n",
                "    \"gender\", \"lead_time_bucket\", \"hour_bucket\", \"age_group\"\n",
                "]\n",
                "\n",
                "label_encoders = {}\n",
                "for col in categorical_cols:\n",
                "    data[col] = data[col].astype(str)\n",
                "    le = LabelEncoder()\n",
                "    data[col + \"_encoded\"] = le.fit_transform(data[col])\n",
                "    label_encoders[col] = le\n",
                "    print(f\"  Encoded: {col} â†’ {len(le.classes_)} classes\")\n",
                "\n",
                "print(\"\\nâœ… All categorical features encoded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ Select Feature Columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "feature_cols = [\n",
                "    \"booking_lead_time_days\",\n",
                "    \"appointment_hour\",\n",
                "    \"past_visit_count\",\n",
                "    \"past_cancellation_count\",\n",
                "    \"past_no_show_count\",\n",
                "    \"is_weekend\",\n",
                "    \"customer_age\",\n",
                "    \"no_show_ratio\",\n",
                "    \"cancellation_ratio\",\n",
                "    \"is_new_customer\",\n",
                "    \"is_loyal_customer\",\n",
                "    \"service_type_encoded\",\n",
                "    \"payment_method_encoded\",\n",
                "    \"branch_encoded\",\n",
                "    \"day_of_week_encoded\",\n",
                "    \"gender_encoded\",\n",
                "    \"lead_time_bucket_encoded\",\n",
                "    \"hour_bucket_encoded\",\n",
                "    \"age_group_encoded\",\n",
                "]\n",
                "\n",
                "# Human-readable feature names for display\n",
                "feature_name_map = {\n",
                "    \"booking_lead_time_days\": \"Booking Lead Time (days)\",\n",
                "    \"appointment_hour\": \"Appointment Hour\",\n",
                "    \"past_visit_count\": \"Past Visit Count\",\n",
                "    \"past_cancellation_count\": \"Past Cancellation Count\",\n",
                "    \"past_no_show_count\": \"Past No-Show Count\",\n",
                "    \"is_weekend\": \"Is Weekend\",\n",
                "    \"customer_age\": \"Customer Age\",\n",
                "    \"no_show_ratio\": \"Historical No-Show Ratio\",\n",
                "    \"cancellation_ratio\": \"Historical Cancellation Ratio\",\n",
                "    \"is_new_customer\": \"Is New Customer\",\n",
                "    \"is_loyal_customer\": \"Is Loyal Customer\",\n",
                "    \"service_type_encoded\": \"Service Type\",\n",
                "    \"payment_method_encoded\": \"Payment Method\",\n",
                "    \"branch_encoded\": \"Branch\",\n",
                "    \"day_of_week_encoded\": \"Day of Week\",\n",
                "    \"gender_encoded\": \"Gender\",\n",
                "    \"lead_time_bucket_encoded\": \"Lead Time Bucket\",\n",
                "    \"hour_bucket_encoded\": \"Hour Bucket\",\n",
                "    \"age_group_encoded\": \"Age Group\",\n",
                "}\n",
                "\n",
                "X = data[feature_cols]\n",
                "y = (data[\"appointment_outcome\"] == \"No-Show\").astype(int)\n",
                "\n",
                "print(f\"âœ… Feature matrix: {X.shape}\")\n",
                "print(f\"   Target: Show={int((y == 0).sum()):,} | No-Show={int(y.sum()):,}\")\n",
                "X.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Train/Test Split + SMOTE\n",
                "\n",
                "We apply **SMOTE (Synthetic Minority Over-sampling Technique)** to the **training set only** to handle the class imbalance. The test set remains untouched to give a realistic evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split first â€” SMOTE is applied ONLY on training data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Before SMOTE:\")\n",
                "print(f\"  Train set: {X_train.shape[0]:,} samples\")\n",
                "print(f\"    Show:    {int((y_train == 0).sum()):,}\")\n",
                "print(f\"    No-Show: {int(y_train.sum()):,}\")\n",
                "print(f\"  Test set:  {X_test.shape[0]:,} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply SMOTE to training data\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "print(f\"After SMOTE:\")\n",
                "print(f\"  Train set: {X_train_smote.shape[0]:,} samples\")\n",
                "print(f\"    Show:    {int((y_train_smote == 0).sum()):,}\")\n",
                "print(f\"    No-Show: {int(y_train_smote.sum()):,}\")\n",
                "print(f\"\\nâœ… Classes are now balanced!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize before vs after SMOTE\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Before SMOTE\n",
                "before_counts = [int((y_train == 0).sum()), int(y_train.sum())]\n",
                "axes[0].bar([\"Show\", \"No-Show\"], before_counts, color=[\"#2ecc71\", \"#e74c3c\"], edgecolor=\"white\")\n",
                "axes[0].set_title(\"Before SMOTE\", fontweight=\"bold\")\n",
                "axes[0].set_ylabel(\"Count\")\n",
                "for i, count in enumerate(before_counts):\n",
                "    axes[0].text(i, count + 30, f\"{count:,}\", ha=\"center\", fontweight=\"bold\")\n",
                "\n",
                "# After SMOTE\n",
                "after_counts = [int((y_train_smote == 0).sum()), int(y_train_smote.sum())]\n",
                "axes[1].bar([\"Show\", \"No-Show\"], after_counts, color=[\"#2ecc71\", \"#e74c3c\"], edgecolor=\"white\")\n",
                "axes[1].set_title(\"After SMOTE\", fontweight=\"bold\")\n",
                "axes[1].set_ylabel(\"Count\")\n",
                "for i, count in enumerate(after_counts):\n",
                "    axes[1].text(i, count + 30, f\"{count:,}\", ha=\"center\", fontweight=\"bold\")\n",
                "\n",
                "plt.suptitle(\"SMOTE: Class Balancing on Training Data\", fontsize=14, fontweight=\"bold\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. XGBoost Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost hyperparameters\n",
                "xgb_model = XGBClassifier(\n",
                "    n_estimators=300,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.05,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    eval_metric=\"logloss\",\n",
                "    verbosity=0,\n",
                "    # Note: We do NOT use scale_pos_weight since SMOTE already balances the classes\n",
                ")\n",
                "\n",
                "print(\"ðŸ”„ Training XGBoost on SMOTE-resampled data...\")\n",
                "xgb_model.fit(X_train_smote, y_train_smote)\n",
                "print(\"âœ… XGBoost training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions on the ORIGINAL (untouched) test set\n",
                "y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Custom threshold (0.8) â€” only flag as No-Show when model is 80%+ confident\n",
                "THRESHOLD = 0.8\n",
                "y_pred = (y_proba >= THRESHOLD).astype(int)\n",
                "\n",
                "print(f\"âœ… Predictions generated with threshold = {THRESHOLD}\")\n",
                "print(f\"   Predicted No-Shows: {y_pred.sum()} out of {len(y_pred)} test samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Evaluation & Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Metrics Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics = {\n",
                "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
                "    \"Precision\": precision_score(y_test, y_pred),\n",
                "    \"Recall\": recall_score(y_test, y_pred),\n",
                "    \"F1 Score\": f1_score(y_test, y_pred),\n",
                "    \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
                "}\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(f\"  XGBoost + SMOTE â€” Threshold = {THRESHOLD}\")\n",
                "print(\"=\" * 50)\n",
                "for name, value in metrics.items():\n",
                "    bar = \"â–ˆ\" * int(value * 30)\n",
                "    print(f\"  {name:12s}: {value:.4f}  {bar}\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Classification Report â€” XGBoost + SMOTE (Threshold = {THRESHOLD})\")\n",
                "print(\"=\" * 60)\n",
                "print(classification_report(y_test, y_pred, target_names=[\"Show\", \"No-Show\"]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
                "            xticklabels=[\"Show\", \"No-Show\"],\n",
                "            yticklabels=[\"Show\", \"No-Show\"],\n",
                "            annot_kws={\"size\": 16})\n",
                "ax.set_title(f\"Confusion Matrix â€” XGBoost + SMOTE (Threshold = {THRESHOLD})\", fontsize=14, fontweight=\"bold\")\n",
                "ax.set_ylabel(\"Actual\", fontsize=12)\n",
                "ax.set_xlabel(\"Predicted\", fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nTrue Positives (correct No-Show):  {cm[1][1]}\")\n",
                "print(f\"False Positives (false alarm):      {cm[0][1]}\")\n",
                "print(f\"True Negatives (correct Show):      {cm[0][0]}\")\n",
                "print(f\"False Negatives (missed No-Show):   {cm[1][0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.4 ROC Curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
                "auc_score = roc_auc_score(y_test, y_proba)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "ax.plot(fpr, tpr, label=f\"XGBoost + SMOTE (AUC = {auc_score:.4f})\", color=\"#e74c3c\", linewidth=2.5)\n",
                "ax.plot([0, 1], [0, 1], \"k--\", alpha=0.5, label=\"Random (AUC = 0.5)\")\n",
                "ax.fill_between(fpr, tpr, alpha=0.1, color=\"#e74c3c\")\n",
                "ax.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
                "ax.set_ylabel(\"True Positive Rate\", fontsize=12)\n",
                "ax.set_title(\"ROC Curve â€” XGBoost + SMOTE\", fontsize=14, fontweight=\"bold\")\n",
                "ax.legend(fontsize=11)\n",
                "ax.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.5 Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fi_df = pd.DataFrame({\n",
                "    \"feature\": X.columns,\n",
                "    \"display_name\": [feature_name_map.get(f, f) for f in X.columns],\n",
                "    \"importance\": xgb_model.feature_importances_\n",
                "}).sort_values(\"importance\", ascending=True)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "bar_colors = [\"#3498db\"] * len(fi_df)\n",
                "# Highlight top 5 features in red\n",
                "for i in range(-5, 0):\n",
                "    bar_colors[i] = \"#e74c3c\"\n",
                "\n",
                "ax.barh(fi_df[\"display_name\"], fi_df[\"importance\"], color=bar_colors, edgecolor=\"white\")\n",
                "ax.set_xlabel(\"Importance\", fontsize=12)\n",
                "ax.set_title(\"Feature Importance â€” XGBoost + SMOTE\", fontsize=14, fontweight=\"bold\")\n",
                "ax.grid(axis=\"x\", alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nðŸ“Š Top 10 Features:\")\n",
                "for _, row in fi_df.sort_values(\"importance\", ascending=False).head(10).iterrows():\n",
                "    bar = \"â–ˆ\" * int(row[\"importance\"] * 100)\n",
                "    print(f\"  {row['display_name']:35s} {row['importance']:.4f} {bar}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.6 Prediction Probability Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "\n",
                "ax.hist(y_proba[y_test == 0], bins=50, alpha=0.7, label=\"Actual Show\", color=\"#2ecc71\", edgecolor=\"white\")\n",
                "ax.hist(y_proba[y_test == 1], bins=50, alpha=0.7, label=\"Actual No-Show\", color=\"#e74c3c\", edgecolor=\"white\")\n",
                "ax.axvline(x=THRESHOLD, color=\"black\", linestyle=\"--\", linewidth=1.5, label=f\"Decision Threshold ({THRESHOLD})\")\n",
                "ax.set_xlabel(\"Predicted No-Show Probability\", fontsize=12)\n",
                "ax.set_ylabel(\"Count\", fontsize=12)\n",
                "ax.set_title(f\"Prediction Probability Distribution (Threshold = {THRESHOLD})\", fontsize=14, fontweight=\"bold\")\n",
                "ax.legend(fontsize=11)\n",
                "ax.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.7 Threshold Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare different thresholds to understand the trade-off\n",
                "print(f\"{'Threshold':<12} {'Recall':<10} {'Precision':<12} {'F1':<10} {'Accuracy':<10}\")\n",
                "print(\"=\" * 54)\n",
                "for t in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
                "    y_pred_t = (y_proba >= t).astype(int)\n",
                "    r = recall_score(y_test, y_pred_t)\n",
                "    p = precision_score(y_test, y_pred_t, zero_division=0)\n",
                "    f = f1_score(y_test, y_pred_t)\n",
                "    a = accuracy_score(y_test, y_pred_t)\n",
                "    marker = \" â—„â”€â”€ current\" if t == THRESHOLD else \"\"\n",
                "    print(f\"  {t:<10} {r:<10.4f} {p:<12.4f} {f:<10.4f} {a:<10.4f}{marker}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "\n",
                "# Save XGBoost model\n",
                "model_path = os.path.join(MODELS_DIR, \"best_model.pkl\")\n",
                "joblib.dump(xgb_model, model_path)\n",
                "print(f\"âœ… Model saved:      {model_path}\")\n",
                "\n",
                "# Save label encoders\n",
                "encoders_path = os.path.join(MODELS_DIR, \"label_encoders.pkl\")\n",
                "joblib.dump(label_encoders, encoders_path)\n",
                "print(f\"âœ… Encoders saved:   {encoders_path}\")\n",
                "\n",
                "# Save model comparison (single model row)\n",
                "results_df = pd.DataFrame({\"XGBoost_SMOTE\": metrics}).T\n",
                "results_path = os.path.join(MODELS_DIR, \"model_comparison.csv\")\n",
                "results_df.to_csv(results_path)\n",
                "print(f\"âœ… Comparison saved: {results_path}\")\n",
                "\n",
                "# Save feature importances\n",
                "fi_save = pd.DataFrame({\n",
                "    \"feature\": X.columns,\n",
                "    \"feature_display\": [feature_name_map.get(f, f) for f in X.columns],\n",
                "    \"importance\": xgb_model.feature_importances_\n",
                "}).sort_values(\"importance\", ascending=False)\n",
                "fi_path = os.path.join(MODELS_DIR, \"feature_importance.csv\")\n",
                "fi_save.to_csv(fi_path, index=False)\n",
                "print(f\"âœ… Feature imp saved: {fi_path}\")\n",
                "\n",
                "# Save metadata\n",
                "metadata = {\n",
                "    \"best_model_name\": \"XGBoost_SMOTE\",\n",
                "    \"threshold\": THRESHOLD,\n",
                "    \"metrics\": metrics,\n",
                "    \"n_features\": X.shape[1],\n",
                "    \"n_train_original\": len(X_train),\n",
                "    \"n_train_after_smote\": len(X_train_smote),\n",
                "    \"n_test\": len(X_test),\n",
                "    \"feature_columns\": list(X.columns),\n",
                "    \"smote_applied\": True,\n",
                "}\n",
                "metadata_path = os.path.join(MODELS_DIR, \"model_metadata.json\")\n",
                "with open(metadata_path, \"w\") as f:\n",
                "    json.dump(metadata, f, indent=2)\n",
                "print(f\"âœ… Metadata saved:   {metadata_path}\")\n",
                "\n",
                "# Save confusion matrix\n",
                "cm_path = os.path.join(MODELS_DIR, \"confusion_matrix.csv\")\n",
                "pd.DataFrame(cm, index=[\"Actual Show\", \"Actual No-Show\"], columns=[\"Pred Show\", \"Pred No-Show\"]).to_csv(cm_path)\n",
                "print(f\"âœ… Confusion matrix: {cm_path}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(f\"  ðŸŽ‰ Pipeline complete! (Threshold = {THRESHOLD})\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ§ª Experiment Space\n",
                "\n",
                "Use the cells below to try new ideas â€” different hyperparameters, SMOTE variants, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try your experiments here!\n",
                "#\n",
                "# Example 1: Tune XGBoost hyperparameters with GridSearchCV\n",
                "# from sklearn.model_selection import GridSearchCV\n",
                "# param_grid = {\n",
                "#     \"n_estimators\": [200, 300, 500],\n",
                "#     \"max_depth\": [4, 6, 8],\n",
                "#     \"learning_rate\": [0.01, 0.05, 0.1],\n",
                "# }\n",
                "# grid = GridSearchCV(XGBClassifier(random_state=42, eval_metric=\"logloss\", verbosity=0),\n",
                "#                     param_grid, cv=5, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
                "# grid.fit(X_train_smote, y_train_smote)\n",
                "# print(f\"Best params: {grid.best_params_}\")\n",
                "# print(f\"Best AUC-ROC: {grid.best_score_:.4f}\")\n",
                "#\n",
                "# Example 2: Try different SMOTE variants\n",
                "# from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
                "# smote_bl = BorderlineSMOTE(random_state=42)\n",
                "# X_train_bl, y_train_bl = smote_bl.fit_resample(X_train, y_train)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}